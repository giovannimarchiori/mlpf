{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-27T16:06:48.079464Z",
     "start_time": "2024-11-27T16:06:47.972923Z"
    }
   },
   "source": [
    "# Compact training script to train a simple NN\n",
    "import mplhep as hep\n",
    "hep.style.use(\"CMS\")\n",
    "import matplotlib\n",
    "matplotlib.rc('font', size=13)\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy import asarray as ar, exp\n",
    "\n",
    "all_pids = [13, -13]\n",
    "\n",
    "def calculate_phi(x, y, z=None):\n",
    "    return np.arctan2(y, x)\n",
    "\n",
    "def calculate_eta(x, y, z):\n",
    "    theta = np.arctan2(np.sqrt(x ** 2 + y ** 2), z)\n",
    "    return -np.log(np.tan(theta / 2))\n",
    "\n",
    "import io\n",
    "\n",
    "def get_dataset(save_ckpt=None):\n",
    "    class CPU_Unpickler(pickle.Unpickler):\n",
    "        def find_class(self, module, name):\n",
    "            if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "                return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "            else:\n",
    "                return super().find_class(module, name)\n",
    "    if save_ckpt is not None:\n",
    "        # check if exists\n",
    "        if os.path.exists(save_ckpt):\n",
    "            print(\"Loading dataset from\", save_ckpt)\n",
    "            #r = pickle.ile exiload(open(save_ckpt, \"rb\"))\n",
    "            r = CPU_Unpickler(open(save_ckpt, \"rb\")).load()\n",
    "            print(\"len x\", len(r[\"x\"]))\n",
    "        else:\n",
    "            r = None\n",
    "    else:\n",
    "        r = None\n",
    "    old_dataset = False\n",
    "    if r is None:\n",
    "        path = \"/eos/user/g/gkrzmanc/results/2024/PID_muons_GT_clusters_025_dataset_save/cluster_features\"\n",
    "        r = {}\n",
    "        n = 0\n",
    "        nmax = 1000000\n",
    "        print(\"Dataset path:\", path)\n",
    "        for file in tqdm.tqdm(os.listdir(path)):\n",
    "            n += 1\n",
    "            if n > nmax: #or os.path.isdir(os.path.join(path, file)):\n",
    "                break\n",
    "            if os.path.isdir(os.path.join(path, file)):\n",
    "                continue\n",
    "            #f = pickle.load(open(os.path.join(path, file), \"rb\"))\n",
    "            f = CPU_Unpickler(open(os.path.join(path, file), \"rb\")).load()\n",
    "            if (len(file) != len(\"8510eujir6.pkl\")): # in case some temporary files are still stored there\n",
    "                continue\n",
    "            #print(f.keys())\n",
    "            if (f[\"e_reco\"].flatten() == 1.).all():\n",
    "                continue  # Some old files, ignore them for now\n",
    "            for key in f:\n",
    "                if key == \"pid_y\":\n",
    "                    if key not in r:\n",
    "                        r[key] = torch.tensor(f[key])\n",
    "                    else:\n",
    "                        r[key] = torch.concatenate([r[key], torch.tensor(f[key])])\n",
    "                elif key != \"y_particles\" or old_dataset:\n",
    "                    if key not in r:\n",
    "                        r[key] = f[key]\n",
    "                    else:\n",
    "                        r[key] = torch.concatenate([torch.tensor(r[key]), torch.tensor(f[key])], axis=0)\n",
    "                else:\n",
    "                    if \"pid_y\" not in f.keys():\n",
    "                        print(key)\n",
    "                        if key not in r:\n",
    "                            r[key] = f[key].pid.flatten()\n",
    "                            r[\"part_coord\"] = f[key].coord\n",
    "                        else:\n",
    "                            r[key] = torch.concatenate((r[key], f[key].pid.flatten()), axis=0)\n",
    "                            r[\"part_coord\"] = torch.concatenate((r[\"part_coord\"], f[key].coord))\n",
    "                            assert len(r[\"part_coord\"]) == len(r[key])\n",
    "    x_names = [\"ecal_E\", \"hcal_E\", \"num_hits\", \"track_p\", \"ecal_dispersion\", \"hcal_dispersion\", \"sum_e\", \"num_tracks\", \"track_p_chis\"]\n",
    "    h_names = [\"hit_x_avg\", \"hit_y_avg\", \"hit_z_avg\"]\n",
    "    h1_names = [\"hit_eta_avg\", \"hit_phi_avg\"]\n",
    "    print(r.keys())\n",
    "    print(\"x shape:\", r[\"x\"].shape)\n",
    "    if old_dataset:\n",
    "        r[\"y_particles\"] = r[\"y_particles\"][:, 6]\n",
    "        xyz = r[\"node_features_avg\"][:, [0, 1, 2]].cpu()\n",
    "        eta_phi = torch.stack([calculate_eta(xyz[:, 0], xyz[:, 1], xyz[:, 2]), calculate_phi(xyz[:, 0], xyz[:, 1])], dim=1)\n",
    "        r[\"x\"] = torch.cat([r[\"x\"], xyz, eta_phi], dim=1)\n",
    "    key = \"e_true\"\n",
    "    true_e_corr_f = r[\"true_e_corr\"]\n",
    "    key = \"e_true_corrected_daughters\"\n",
    "    true_e_corr_f = r[\"e_true_corrected_daughters\"] / r[\"e_reco\"] - 1\n",
    "    if \"pid_y\" in r:\n",
    "        r[\"y_particles\"] = r[\"pid_y\"]\n",
    "    abs_energy_diff = np.abs(r[\"e_true_corrected_daughters\"] - r[\"e_true\"])\n",
    "    electron_brems_mask = (r[\"pid_y\"] == 11) & (abs_energy_diff > 0)\n",
    "    if save_ckpt is not None and not os.path.exists(save_ckpt):\n",
    "        pickle.dump(r, open(save_ckpt, \"wb\"))\n",
    "    return r[\"x\"], x_names + h_names + h1_names, r[\"e_true\"], r[key], r[\"e_reco\"], r[\"y_particles\"], r[\"coords_y\"] #torch.concatenate([r[\"eta\"].reshape(1, -1), r[\"phi\"].reshape(1, -1)], axis=0).T\n",
    "def get_split(ds, overfit=False):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x, _, y, etrue, _, pids, positions = ds\n",
    "    xtrain, xtest, ytrain, ytest, energiestrain, energiestest, pid_train, pid_test, pos_train, pos_test = train_test_split(\n",
    "        x, y, etrue, pids, positions, test_size=0.2, random_state=42\n",
    "    )\n",
    "    if overfit:\n",
    "        return xtrain[:100], xtest[:100], ytrain[:100], ytest[:100], energiestrain[:100], energiestest[:100], pid_train[:100], pid_test[:100]\n",
    "    return xtrain, xtest, ytrain, ytest, energiestrain, energiestest, pid_train, pid_test, pos_train, pos_test # 8,9 are pos train and pos test\n"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:06:52.765791Z",
     "start_time": "2024-11-27T16:06:48.769923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds = get_dataset()\n",
    "split = get_split(ds)"
   ],
   "id": "66152a32852a7199",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /eos/user/g/gkrzmanc/results/2024/PID_muons_GT_clusters_025_dataset_save/cluster_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/56 [00:00<?, ?it/s]/tmp/gkrzmanc/ipykernel_2983/1648975163.py:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  r[key] = torch.concatenate([torch.tensor(r[key]), torch.tensor(f[key])], axis=0)\n",
      "100%|██████████| 56/56 [00:03<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['x', 'e_true', 'e_reco', 'true_e_corr', 'e_true_corrected_daughters', 'coords_y', 'pid_y'])\n",
      "x shape: torch.Size([15464, 16])\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:06:54.131064Z",
     "start_time": "2024-11-27T16:06:54.105941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filter = split[6].abs()==13\n",
    "filter.sum() # Muons\n"
   ],
   "id": "dd65cef42622f664",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(56)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:06:54.360022Z",
     "start_time": "2024-11-27T16:06:54.348898Z"
    }
   },
   "cell_type": "code",
   "source": "split[0][:, 9]",
   "id": "f1094dcafc32f802",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:06:55.354529Z",
     "start_time": "2024-11-27T16:06:55.291322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_muon_hits_muons = split[0][:, 10][filter]\n",
    "num_muon_hits_other = split[0][:, 10][~filter]\n",
    "e_muon_hits_muons = split[0][:, 9][filter]\n",
    "e_muon_hits_other = split[0][:, 9][~filter]"
   ],
   "id": "aca1a639e62e5862",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:06:56.314302Z",
     "start_time": "2024-11-27T16:06:56.274904Z"
    }
   },
   "cell_type": "code",
   "source": "num_muon_hits_muons",
   "id": "b080c41b16d4cad3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  8.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,  7.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0., 11.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:06:56.538135Z",
     "start_time": "2024-11-27T16:06:56.506471Z"
    }
   },
   "cell_type": "code",
   "source": "num_muon_hits_muons.mean(), num_muon_hits_other.mean()",
   "id": "9e673dceb800fa0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5536), tensor(0.1038))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:06:56.856095Z",
     "start_time": "2024-11-27T16:06:56.765174Z"
    }
   },
   "cell_type": "code",
   "source": "(num_muon_hits_muons != 0).float().mean(), (num_muon_hits_other != 0).float().mean()",
   "id": "303d2a84e725acbd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0893), tensor(0.0249))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:06:57.018592Z",
     "start_time": "2024-11-27T16:06:56.955583Z"
    }
   },
   "cell_type": "code",
   "source": "e_muon_hits_muons.mean(), e_muon_hits_other.mean()",
   "id": "a4048729f418c30b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6.5641e-05), tensor(3.5406e-05))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:06:57.260518Z",
     "start_time": "2024-11-27T16:06:57.222510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "([per_graph_e_hits_ecal / sum_e,\n",
    "                                per_graph_e_hits_hcal / sum_e,\n",
    "                                num_hits, track_p,\n",
    "                                per_graph_e_hits_ecal_dispersion,\n",
    "                                per_graph_e_hits_hcal_dispersion,\n",
    "                                sum_e, num_tracks, torch.clamp(chis_tracks, -5, 5),\n",
    "                                per_graph_e_hits_muon / sum_e,\n",
    "                             ]).T'''"
   ],
   "id": "2965e2c790884895",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n([per_graph_e_hits_ecal / sum_e,\\n                                per_graph_e_hits_hcal / sum_e,\\n                                num_hits, track_p,\\n                                per_graph_e_hits_ecal_dispersion,\\n                                per_graph_e_hits_hcal_dispersion,\\n                                sum_e, num_tracks, torch.clamp(chis_tracks, -5, 5),\\n                                per_graph_e_hits_muon / sum_e,\\n                             ]).T'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:06:57.463012Z",
     "start_time": "2024-11-27T16:06:57.452019Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "19d7b6e8636a00a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "63188eaa39ac55af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
